---
title: "Downstream Analysis of PiGx-CRISPR outputs"
output: html_document
date: '`r date()`'
params: 
  ampliconName: ''
  indelsFolder: ''
  comparisonsFile: '' 
  workdir: ''
  prefix: ''
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = params$workdir)
library(ggplot2)
library(ggrepel)
library(data.table)
library(plotly)
library(knitr)
library(parallel)
library(pbapply)
```

The goal of this script is to compare indel scores/frequencies between two sample groups in
a case-control setting - and extract important sites that are enriched/depleted in the case 
samples compared to the control samples. 

# Input Settings
```{r printInputSettings}
ampliconName <- params$ampliconName
indelsFolder <- params$indelsFolder
comparisonsFile <- params$comparisonsFile
prefix <- params$prefix
workdir <- params$workdir

inputParameterDesc <- c('Amplicon Name',
                        'indels folder path', 
                        'Table of comparisons to make',
                        'Prefix for output files',
                        'Working directory'
                     )
inputParameterValues <- c(ampliconName, 
                          indelsFolder,
                          comparisonsFile,
                          prefix, 
                          workdir)
inputSettings <- data.frame(parameters = inputParameterDesc,
                            values = inputParameterValues,
                            stringsAsFactors = FALSE)
DT::datatable(data = inputSettings,
              extensions = 'FixedColumns',
              options = list(fixedColumns = TRUE,
                         scrollX = TRUE,
                         pageLength = nrow(inputSettings),
                         dom = 't'))
```

# Comparisons to make 
```{r parse-comparison-table}
comp <- data.table::fread(comparisonsFile)
if(!ampliconName %in% comp$amplicon) {
  stop("There are no comparisons available for amplicon:",ampliconName,
       "in the file:",comparisonsFile,"\n")
}
comp <- comp[amplicon %in% ampliconName]
DT::datatable(data = comp, filter = 'bottom')
```

# Prepare datasets for comparison 
```{r}
#
#import indel/coverage profile stats for samples listed in comparisons
#TODO: allow for multiple case/control samples (comma-separated), currently
#this only supports one case versus one control sample comparison
samples <- unique(c(comp$case_samples, comp$control_samples))
coverageStats <- as.data.table(do.call(rbind, lapply(samples, function(sampleName) {
  f <- file.path(indelsFolder, paste0(sampleName, '.coverageStats.tsv'))
  if(file.exists(f)) {
    dt <- data.table::fread(f)
    return(dt)
  } else {
    stop("Can't open coverageStats.tsv file for sample",sampleName,
            "at",f,"\n")
  }
})))

# sanity check 
summ <- table(coverageStats$sample)
if(min(summ) != max(summ)) {
  print(summ)
  stop("Not all samples in the file",f,"contain the same number of measurements",
       "see: table(coverageStats$sample)")
}

```

# pairwise comparison of samples 
```{r}
#coverageStats: data.frame output from getIndelStats.R function 
comparePerBaseScores <- function(coverageStats, caseSample, controlSample, indelType) {
  case <- coverageStats[sample == caseSample,]
  control <- coverageStats[sample == controlSample,]
  
  #calculate fold-change per base
  caseCov <- case[['cov']]
  caseScore <- case[[indelType]]
  
  controlCov <- control[['cov']]
  controlScore <- control[[indelType]]
  
  A <- ifelse(controlCov > 0, controlScore/controlCov, 0)
  B <- ifelse(caseCov > 0, caseScore/caseCov, 0)
  
  #log fold change as case divided by control
  log2FoldChange <- log2(B/A)
  #percent difference between case and control
  difference <- B - A
  
  #p values  - for each base, compare indel probabilities 
  #and get a fisher exact's p value
  results <- do.call(rbind, lapply(1:length(caseScore), function(i) {
    #contingency matrix
    M <- matrix(c(caseScore[i], controlScore[i], 
                caseCov[i] - caseScore[i], controlCov[i] - controlScore[i]), nrow = 2)
    t <- fisher.test(M)
    oddsRatio <- as.numeric(t$estimate)
    pVal <- t$p.value
    return(data.frame('bp' = i, 'oddsRatio' = oddsRatio, 'pval' = pVal))
  }))
  
  results$padj <- p.adjust(results$pval)
  
  results <- merge(data.frame('bp' = case$bp, 
                        'case' = caseSample, 
                        'control' = controlSample,
                        'caseScore' = caseScore,
                        'caseCov' = caseCov, 
                        'controlScore' = controlScore,
                        'controlCov' = controlCov,
                        'indelType' = indelType,
                        'log2FoldChange' = log2FoldChange, 
                        'difference' = difference), results, by = 'bp')
          
  return(results)
}
```

```{r}

printBedGraphFile <- function(outFile, trackInfo, df) {
  #write bedgraph file
  trackDefinition <- paste0("track type=bedGraph name=",trackInfo)
  writeLines(text = trackDefinition, con = outFile)
  #convert coordinates to 0 based (start, end) form
  df$start <- df$start - 1
  write.table(x = df,
              file = outFile,
              quote = F, sep = '\t', col.names = F, row.names = F, append = T)
}

results <- as.data.frame(do.call(rbind,  lapply(X = comp$comparison, 
                                                           FUN = function(x) {
  r <- do.call(rbind, lapply(c('ins', 'del', 'indel'), function(indelType) {
    comparePerBaseScores(coverageStats = coverageStats, 
                         caseSample = comp[comparison == x,]$case_samples, 
                         controlSample = comp[comparison == x,]$control_samples, 
                         indelType = indelType)
  }))
  r$comparison <- x
  return(r)
})), stringsAsFactors = FALSE)

pdf(file = file.path(workdir, paste0(ampliconName, ".comparisons.plots.pdf")))
plots <- lapply(unique(results$comparison), function(x){
  plots <- lapply(unique(results$indelType), function(indelType) {
    df <- results[results$comparison == x & results$indelType == indelType,]
    
    #segment the profiles and calculate average p-values in each segment
    segments <- as.data.frame(fastseg::fastseg(df$difference))
    segments$mean.padj <- sapply(1:nrow(segments), function(i) {
      mean(df[df$bp >= segments[i, 'start'] & df$bp <= segments[i, 'end'],]$padj)
    })
    #map p-values to stars for visualisation
    segments$label <- gtools::stars.pval(segments$mean.padj)
    
    p <- ggplot(df, aes(x = bp, y = difference)) + 
      geom_point(aes(color = padj < 0.05)) + 
      geom_segment(data = segments, aes(x = start, xend = end, 
                                        y = seg.mean, yend = seg.mean)) + 
      geom_text(data = segments, aes(x = (start+end)/2, y = seg.mean, 
                                     label = label)) + 
      ggtitle(paste0("Case sample: ",unique(as.character(df$case)), 
                     "\nControl sample: ",unique(as.character(df$control))), 
              subtitle = paste0("Indel type: ", indelType)) + 
      theme_bw() 
    print(p)
    
    ## print the 'difference' value for each base position as a bedgraph file
    outfile <- file.path(workdir, paste0(ampliconName, '.comparison.', 
                                         x, '.', indelType,  '.bedgraph'))
    
    df.bg <- data.frame('seqname' = ampliconName, 
                        'start' = df$bp,
                        'end' = df$bp, 
                        'score' = df$difference, stringsAsFactors = FALSE)

    printBedGraphFile(outFile = outfile,
                trackInfo = paste(x, 'per base percent difference', indelType),
                df = df.bg)
    return(p)
  })
  names(plots) <- unique(results$indelType)
  return(plots)
})
names(plots) <- unique(results$comparison)
#close pdf connection
dev.off()

#save stats to file
statsOutFile <- file.path(workdir, paste0(ampliconName, '.comparison.stats.tsv'))
write.table(x = results, file = statsOutFile, quote = FALSE, sep = '\t', row.names = FALSE)
```

## Significantly Affected Base Positions/Segments 

```{r plotIndelProfilesPlots}
out = NULL
for (comparison in names(plots)) {
  out = c(out, knitr::knit_expand(text='### Comparison {{comparison}} {.tabset} \n\n'))
  for (indelType in names(plots[[comparison]])) {
    p <- ggplotly(plots[[comparison]][[indelType]])
    out = c(out, knitr::knit_expand(text='#### {{indelType}} \n\n {{p}} \n\n'))
  }
}
```

`r paste(knit(text = out), collapse = '\n')`

# Comparison of indel frequencies


## Deletion frequencies 

First, get deletions and add coverage values for each deletion
```{r}
samples <- unique(c(comp$case_samples, comp$control_samples))
indels <- as.data.table(do.call(rbind, lapply(samples, function(sampleName) {
  f <- file.path(indelsFolder, paste0(sampleName, '.indels.unfiltered.tsv'))
  if(file.exists(f)) {
    dt <- data.table::fread(f)
    return(dt)
  } else {
    stop("Can't open indels.unfiltere.tsv file for sample",sampleName,
            "at",f,"\n")
  }
})))
#collapse indels
indels <- indels[,length(unique(readID)), by = c('seqname', 'sample', 'start', 'end', 'indelType')]
colnames(indels)[6] <- 'ReadSupport'

deletions <- indels[indelType == 'D']

#assign ids for each deletion that represents the coordinates of the deletion
deletions$id <- paste(deletions$seqname, deletions$start, deletions$end, sep = ':')

#create a table where each deletion found in all samples is represented for each sample
#whether or not the deletion is found in the corresponding sample

deletions <- melt(dcast(deletions, id ~ sample, value.var = 'ReadSupport'), id.vars = 'id')
#assign NA values to 0
deletions[is.na(value)]$value <- 0
colnames(deletions) <- c('id', 'sample', 'ReadSupport')

deletions <- cbind(do.call(rbind, strsplit(deletions$id, ':')), deletions)
colnames(deletions)[1:3] <- c('seqname', 'start', 'end')
deletions$start <- as.numeric(deletions$start)
deletions$end <- as.numeric(deletions$end)

#get mean coverage at the bases spanned by each deletion 
deletions <- do.call(rbind, lapply(unique(deletions$sample), function(s) {
  dt <- deletions[sample == s]
  
  #make sure the coverage values start from the first base position
  #if not, fill those positions up to first coverage value with zeroes 
  coverage <- coverageStats[sample == s][order(bp)]
  coverage <- c(rep(0, coverage[1,]$bp - 1), 
                coverage$cov)
  
  dt$medianCoverage <- apply(dt, 1, function(x) {
    median(coverage[x[['start']]:x[['end']]])
  })
  return(dt)
}))
deletions$freq <- deletions$ReadSupport/deletions$medianCoverage
```

Make plots to compare case versus control samples 
```{r compare_del_freq}
#dt: deletions/insertions table
#minReadSupport mininum number of reads in sum of the samples
#minFreq minimum frequency in sum of the samples
getSignificantIndels <- function(dt, caseSample, controlSample, minReadSupport = 5, minFreq = 10^-4) {
  #subset for control samples
  dt <- droplevels(dt[sample %in% c(caseSample, controlSample)])
  
  #independent filtering for read support
  dt <- dt[id %in% dt[,sum(ReadSupport), by = id][V1 > minReadSupport]$id]
  
  #independent filtering for frequency
  dt <- dt[id %in% dt[,sum(freq), by = id][V1 > minFreq]$id]
  
  if(nrow(dt) == 0) {
    cat("warning: getSignificantIndels => No significant indels left after filtering")
    return(NULL)
  }
  
  # median coverage values as integer
  dt$medianCoverage <- as.integer(dt$medianCoverage)
  
  case <- dt[sample == caseSample]
  ctrl <- dt[sample == controlSample]

  mdt <- merge(case[,c('id', 'ReadSupport', 'medianCoverage')], 
        ctrl[,c('id', 'ReadSupport', 'medianCoverage')], 
        by = 'id', all = TRUE)
  
  results <- cbind(mdt, do.call(rbind, apply(mdt, 1, function(x) {
    #add a constant value (5) to each category to avoid Inf values
    x <- as.numeric(x[2:5])
    test <- fisher.test(matrix(c(x[1], x[3], 
                                 x[2] - x[1], x[4] - x[3]), nrow = 2) + 1, 
                        alternative = 'two.sided')
    return(data.frame('pval' = test$p.value, 'oddsRatio' = as.numeric(test$estimate)))
  })))
  
  results$padj <- p.adjust(results$pval, method = 'BH')
 
  return(results)
}

plots <- pbapply::pblapply(unique(comp$comparison), function(cmp) {
  caseSample <- comp[comparison == cmp]$case_samples
  controlSample <- comp[comparison == cmp]$control_samples
  
  #get significance values for each deletion
  sig <- getSignificantIndels(dt = deletions,
                              caseSample = caseSample,
                              controlSample = controlSample, 
                              minReadSupport = 1, 
                              minFreq = 10^-6)
  if(is.null(sig)) {
    return(list("volcano_plot" = NULL, "segment_plot" = NULL))
  }
  results <- merge(unique(deletions[,c('seqname','start', 'end', 'id')]), 
                   sig, 
                   by = 'id')
  #save results table
  write.table(x = results[order(pval)], 
              file = file.path(workdir, paste0(ampliconName, ".comparison.", 
                                               cmp, ".stats.deletions.tsv")), 
              row.names = FALSE, quote = FALSE, sep = '\t')
  
  #make a volcano plot of deletions 
  p1 <- ggplot(results, aes(y = -log10(padj), x = log2(oddsRatio))) + 
    geom_point(aes(color = padj < 0.01)) + 
    #add labels to top 10
    geom_text_repel(data = results[order(padj)][1:10], aes( label = id)) +
    ggtitle(label = "Comparison of detected deletions", 
            subtitle = paste0("Case: ",caseSample, "\nControl: ",controlSample))
  
  #make a segment plot of deletions 
  p2 <- ggplot(results[padj < 0.01]) + 
    geom_linerange(aes(x = log2(oddsRatio), ymin = start, ymax = end)) +
    geom_point(data = results[padj < 0.01], aes(x = log2(oddsRatio), y = start), size = 1, color = 'red') + 
    geom_point(data = results[padj < 0.01], aes(x = log2(oddsRatio), y = end), size = 1, color = 'blue') +
    ggtitle(label = "Comparison of deletions\n with significant difference (adjusted p.val < 0.01)", 
            subtitle = paste0("Case: ",caseSample, "\nControl: ",controlSample)) + 
    coord_flip()
  
  return(list("volcano_plot" = p1, "segment_plot" = p2))
})
names(plots) <- unique(comp$comparison)
```

```{r, echo = FALSE}
#Save .tsv files for each sample with frequency values of each deletion
for(s in unique(deletions$sample)){
  outFile <- file.path(workdir, paste0(ampliconName,".deletionFrequencies.",s,".tsv"))
  write.table(x = deletions[sample == s & ReadSupport > 0][order(freq, decreasing = T)], file = outFile, sep = '\t', row.names = FALSE, quote = FALSE)
}
```


```{r plotComparison, results='asis', fig.height=8, fig.width=10}
for (cmp in names(plots)) {
  cat('### Comparison:',cmp,'{.tabset}\n\n')
  for(i in names(plots[[cmp]])) {
    cat('#### ',i,'\n\n')
    p <- plots[[cmp]][[i]]
    if(!is.null(p)) {
      print(p)
    } else {
      cat("No plot to show\n\n")
    }
    cat("\n\n")
  }
  cat("\n\n")
}
```


## Insertion frequencies

First, get insertions and add coverage values for each insertion
```{r}
samples <- unique(c(comp$case_samples, comp$control_samples))
insertions <- as.data.table(do.call(rbind, lapply(samples, function(sampleName) {
  f <- file.path(indelsFolder, paste0(sampleName, '.insertedSequences.tsv'))
  if(file.exists(f)) {
    dt <- data.table::fread(f)
    dt$sample <- sampleName
    return(dt)
  } else {
    stop("Can't open .insertedSequences.tsv file for sample",sampleName,
            "at ",f,"\n")
  }
})))
#collapse 
insertions <- insertions[,length(unique(name)), 
                         by = c('seqname', 'sample', 'start', 
                                'insertedSequence', 
                                'insertionWidth')]
colnames(insertions)[6] <- 'ReadSupport'


#assign ids for each deletion that represents the coordinates of the deletion
insertions$id <- paste(insertions$seqname, insertions$start, 
                       insertions$insertedSequence, sep = ':')

#create a table where each insertion found in all samples is represented for each sample
#whether or not the insertion is found in the corresponding sample

insertions <- melt(dcast(insertions, id ~ sample, value.var = 'ReadSupport'), id.vars = 'id')
#assign NA values to 0
insertions[is.na(value)]$value <- 0
colnames(insertions) <- c('id', 'sample', 'ReadSupport')

insertions <- cbind(do.call(rbind, strsplit(insertions$id, ':')), insertions)
colnames(insertions)[1:3] <- c('seqname', 'start', 
                                'insertedSequence')
insertions$start <- as.numeric(insertions$start)

#get coverage at the insertion site 
insertions <- do.call(rbind, lapply(unique(insertions$sample), function(s) {
  dt <- insertions[sample == s]
  
  #make sure the coverage values start from the first base position
  #if not, fill those positions up to first coverage value with zeroes 
  coverage <- coverageStats[sample == s][order(bp)]
  coverage <- c(rep(0, coverage[1,]$bp - 1), 
                coverage$cov)
  
  #in the case of insertions, pick the coverage only at the site of insertion
  dt$medianCoverage <- coverage[dt$start]
  return(dt)
}))
insertions$freq <- insertions$ReadSupport/insertions$medianCoverage
```


Make plots to compare case versus control samples 
```{r compare_ins_freq}
plots <- pbapply::pblapply(unique(comp$comparison), function(cmp) {
  caseSample <- comp[comparison == cmp]$case_samples
  controlSample <- comp[comparison == cmp]$control_samples
  
  
  #get significance values for each insertion
  sig <- getSignificantIndels(dt = insertions,
                              caseSample = caseSample,
                              controlSample = controlSample, 
                              minReadSupport = 1, 
                              minFreq = 10^-6)
  if(is.null(sig)) {
    return(list("volcano_plot" = NULL, "segment_plot" = NULL))
  }
  
  results <- merge(unique(insertions[,c('seqname','start', 'id')]), 
                   sig, 
                   by = 'id')
  
  #save results table
  write.table(x = results[order(pval)], 
              file = file.path(workdir, paste0(ampliconName, ".comparison.", 
                                               cmp, ".stats.insertions.tsv")), 
              row.names = FALSE, quote = FALSE, sep = '\t')
  
  #make a volcano plot of deletions 
  p1 <- ggplot(results, aes(y = -log10(padj), x = log2(oddsRatio))) + 
    geom_point(aes(color = padj < 0.01)) + 
    #add labels to top 10
    geom_text_repel(data = results[order(padj)][1:10], aes( label = id)) +
    ggtitle(label = "Comparison of detected insertions", 
            subtitle = paste0("Case: ",caseSample, "\nControl: ",controlSample))
  
  #make a segment plot of deletions 
  results$insertionWidth <- sapply(strsplit(results$id, ":"), function(x) nchar(x[3]))
  p2 <- ggplot(results[padj < 0.01]) + 
    geom_linerange(aes(x = log2(oddsRatio), 
                       ymin = start - insertionWidth/2, 
                       ymax = start + insertionWidth/2), 
                   alpha = 0.5) +
    geom_point(data = results[padj < 0.01], 
               aes(x = log2(oddsRatio), y = start), 
               size = 1, shape = 24, fill = 'red') + 
    ggtitle(label = "Comparison of insertions\n with significant difference (adjusted p.val < 0.01)", 
            subtitle = paste0("Case: ",caseSample, "\nControl: ",controlSample)) + 
    coord_flip()
  
  return(list("volcano_plot" = p1, "segment_plot" = p2))
})
names(plots) <- unique(comp$comparison)
```

```{r, echo = FALSE}
#Save .tsv files for each sample with frequency values of each deletion
for(s in unique(insertions$sample)) {
  outFile <- file.path(workdir, paste0(ampliconName,".insertionFrequencies.",s,".tsv"))
  write.table(x = insertions[sample == s & ReadSupport > 0][order(freq, decreasing = T)], file = outFile, sep = '\t', row.names = FALSE, quote = FALSE)
}
```


```{r plotInsComparison, results='asis', fig.height=8, fig.width=10}
for (cmp in names(plots)) {
  cat('### Comparison:',cmp,'{.tabset}\n\n')
  for(i in names(plots[[cmp]])) {
    cat('#### ',i,'\n\n')
    p <- plots[[cmp]][[i]]
    if(!is.null(p)) {
      print(p)
    } else {
      cat("No plot to show\n\n")
    }
    cat("\n\n")
  }
  cat("\n\n")
}
```

# Session Information

```{r sessionInfo}
print(sessionInfo())
```

